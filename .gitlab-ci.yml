image: node:18

# DO NOT EDIT! THIS IS GENERATED FILE

stages:
  - check
  - previous-image
  - build
  - latest-image
  - deploy
  - deploy-previous

cache:
  paths:
    - .cache
    - .cache_images
    # - node_modules

variables:
  REPO_NAME: $CI_PROJECT_NAME
  VERBOSE: 'true'
  RELEASE: $CI_COMMIT_SHORT_SHA
  KUBECONFIG: /etc/deploy/config
  PROJECT_NAME: sport

check:
  stage: check
  image: registry.gitlab.com/making.ventures/images/node-with-tools
  before_script:
    - yarn install --frozen-lockfile
  script:
    - ./check.sh
  after_script:
    - chmod +x ci-notify.sh
    - >
      if [ $CI_JOB_STATUS != 'success' ]; then
        sh ci-notify.sh "ðŸ†˜ $CI_JOB_NAME failed"
      else
        sh ci-notify.sh "âœ… $CI_JOB_NAME success"
      fi

tag-previous-with-sha:
  extends: .tag-image
  stage: previous-image
  only:
    - master
    - /^master-.*$/
    - release
    - /^release-.*$/
  allow_failure: true # First run won't be able to create previous image
  variables:
    TAG_ORIGIN: :${CI_COMMIT_REF_SLUG}
    TAG_DESTINATION: :${CI_COMMIT_REF_SLUG}-previous-for-${CI_COMMIT_SHA}

build:
  stage: build
  image:
    name: gcr.io/kaniko-project/executor:debug
    entrypoint: ['']
  before_script:
    - mkdir -p /kaniko/.docker
    - echo "{\"auths\":{\"$CI_REGISTRY\":{\"username\":\"$CI_REGISTRY_USER\",\"password\":\"$CI_REGISTRY_PASSWORD\"}}}" > /kaniko/.docker/config.json
    # - /kaniko/warmer --cache-dir=$CI_PROJECT_DIR/.cache_images --image=browserless/chrome
    - echo TAG1 "${CI_COMMIT_REF_SLUG}"
    - echo TAG2 "${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}"
  script:
    - /kaniko/executor
      --cache-dir=$CI_PROJECT_DIR/.cache_images
      --context ${CI_PROJECT_DIR}
      --dockerfile ${CI_PROJECT_DIR}/Dockerfile
      --build-arg GIT_COMMIT=${CI_COMMIT_SHA}
      --destination ${CI_REGISTRY_IMAGE}:${CI_COMMIT_REF_SLUG}
      --destination ${CI_REGISTRY_IMAGE}:${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}
      --single-snapshot
  only:
    - master
    - /^master-.*$/
    - release
    - /^release-.*$/

tag-latest:
  extends: .tag-image
  stage: latest-image
  only:
    - master
  variables:
    TAG_ORIGIN: master
    TAG_DESTINATION: latest

.tag-image:
  image:
    name: gcr.io/go-containerregistry/crane:debug
    entrypoint: ['']
  script:
    - echo TAG_DESTINATION ${TAG_DESTINATION}
    - crane auth login -u $CI_REGISTRY_USER -p $CI_REGISTRY_PASSWORD $CI_REGISTRY
    - crane cp ${CI_REGISTRY_IMAGE}:${TAG_ORIGIN} ${CI_REGISTRY_IMAGE}:${TAG_DESTINATION}
  variables:
    GIT_STRATEGY: none

deploy-dev:
  extends: .deploy-dev
  stage: deploy
  variables:
    ENV: "dev"
    CLUSTER_NAME: "stage01"
    TAG: ":${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}"
  only:
    - master
    - /^master-.*$/

deploy-prod:
  extends: .deploy-prod
  stage: deploy
  variables:
    ENV: "prod"
    CLUSTER_NAME: "stage01"
    TAG: ":${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}"
  only:
    - release
    - /^release-.*$/

deploy-dev-previous:
  extends: .deploy-dev
  stage: deploy-previous
  when: manual
  variables:
    ENV: "dev"
    CLUSTER_NAME: "stage01"
    TAG: ":${CI_COMMIT_REF_SLUG}-previous-for-${CI_COMMIT_SHA}"
  only:
    - master
    - /^master-.*$/

deploy-prod-previous:
  extends: .deploy-prod
  stage: deploy-previous
  when: manual
  variables:
    ENV: "prod"
    CLUSTER_NAME: "stage01"
    TAG: ":${CI_COMMIT_REF_SLUG}-previous-for-${CI_COMMIT_SHA}"
  only:
    - release
    - /^release-.*$/

.deploy-dev:
  extends: .deploy-ui
  stage: deploy
  when: on_success
  only:
    - master
    - /^master-.*$/
  tags:
    - dev
  variables:
    ENV: "dev"
    DEV: "false"
    HOST: "making.ventures"
    ROOT_ENABLED: "false"
    KUBE_CONFIG: ${KUBE_STAGE01_CONFIG}
    TAG: ":${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}"
    ADMIN_RECAPTCHA_PUBLIC_KEY: ${DEV_ADMIN_RECAPTCHA_PUBLIC_KEY}
    CHECK_LOGIN_IFRAME: ${DEV_CHECK_LOGIN_IFRAME}
    DOCKER_REGISTRY_DOMAIN: ${DEV_DOCKER_REGISTRY_DOMAIN}
    DOCKER_REGISTRY_PASSWORD: ${DEV_DOCKER_REGISTRY_PASSWORD}
    DOCKER_REGISTRY_USERNAME: ${DEV_DOCKER_REGISTRY_USERNAME}
    ENDPOINT: ${DEV_ENDPOINT}
    OIDC_ADM_CLIENT_ID: ${DEV_OIDC_ADM_CLIENT_ID}
    OIDC_ADM_ISSUER: ${DEV_OIDC_ADM_ISSUER}
    OIDC_ADM_LOGOUT_TYPE: ${DEV_OIDC_ADM_LOGOUT_TYPE}
    OIDC_ADM_REALM: ${DEV_OIDC_ADM_REALM}
    OIDC_ADM_URL: ${DEV_OIDC_ADM_URL}

.deploy-prod:
  extends: .deploy-ui
  stage: deploy
  when: manual
  only:
    - release
    - /^release-.*$/
  tags:
    - prod
  variables:
    ENV: "prod"
    DEV: "false"
    HOST: "sportdata.tech"
    ROOT_ENABLED: "true"
    KUBE_CONFIG: ${KUBE_STAGE01_CONFIG}
    TAG: ":${CI_COMMIT_REF_SLUG}-${CI_COMMIT_SHA}"
    ADMIN_RECAPTCHA_PUBLIC_KEY: ${PROD_ADMIN_RECAPTCHA_PUBLIC_KEY}
    CHECK_LOGIN_IFRAME: ${PROD_CHECK_LOGIN_IFRAME}
    DOCKER_REGISTRY_DOMAIN: ${PROD_DOCKER_REGISTRY_DOMAIN}
    DOCKER_REGISTRY_PASSWORD: ${PROD_DOCKER_REGISTRY_PASSWORD}
    DOCKER_REGISTRY_USERNAME: ${PROD_DOCKER_REGISTRY_USERNAME}
    ENDPOINT: ${PROD_ENDPOINT}
    OIDC_ADM_CLIENT_ID: ${PROD_OIDC_ADM_CLIENT_ID}
    OIDC_ADM_ISSUER: ${PROD_OIDC_ADM_ISSUER}
    OIDC_ADM_LOGOUT_TYPE: ${PROD_OIDC_ADM_LOGOUT_TYPE}
    OIDC_ADM_REALM: ${PROD_OIDC_ADM_REALM}
    OIDC_ADM_URL: ${PROD_OIDC_ADM_URL}

.deploy-ui:
  extends: .deploy
  variables:
    DEPLOY_KIND: "ui"

.deploy:
  image:
    name: alpine/helm:3.13.1
    entrypoint: [""]
  before_script:
    - mkdir -p /etc/deploy
    - cp $KUBE_CONFIG $KUBECONFIG
  script:
    - NAMESPACE=${NAMESPACE:-"sport-${ENV}"}
    - echo TAG ${TAG}
    - echo NAMESPACE ${NAMESPACE}
    - echo chart ${NAMESPACE}-${DEPLOY_KIND}

    - helm upgrade
      --install
      --wait ${NAMESPACE}-${DEPLOY_KIND} chart
      --timeout 3600s
      -f chart/values_${ENV}.yaml
      --namespace ${NAMESPACE}
      --create-namespace
      --set "global.projectName=${PROJECT_NAME}"
      --set "global.clusterName=${CLUSTER_NAME}"
      --set "global.env=${ENV}"
      --set "global.deployKind=${DEPLOY_KIND}"
      --set "app.tag=${TAG}"
      --set "ingress.host=${HOST}"
      --set "style=${STYLE}"
      --set "ingress.rootEnabled=${ROOT_ENABLED}"
      --set "admin.recaptcha.publicKey=${ADMIN_RECAPTCHA_PUBLIC_KEY}"
      --set "checkLoginIframe=${CHECK_LOGIN_IFRAME}"
      --set "dockerRegistry.domain=${DOCKER_REGISTRY_DOMAIN}"
      --set "dockerRegistry.password=${DOCKER_REGISTRY_PASSWORD}"
      --set "dockerRegistry.username=${DOCKER_REGISTRY_USERNAME}"
      --set "endpoint=${ENDPOINT}"
      --set "oidc.adm.clientId=${OIDC_ADM_CLIENT_ID}"
      --set "oidc.adm.issuer=${OIDC_ADM_ISSUER}"
      --set "oidc.adm.logoutType=${OIDC_ADM_LOGOUT_TYPE}"
      --set "oidc.adm.realm=${OIDC_ADM_REALM}"
      --set "oidc.adm.url=${OIDC_ADM_URL}"
  after_script:
    - >
      if [ $CI_JOB_STATUS != 'success' ]; then
        sh ci-notify.sh "ðŸ†˜ $CI_JOB_NAME failed"
      else
        sh ci-notify.sh "âœ… $CI_JOB_NAME success"
      fi
